"""
Desafio CH5 ‚Äî Interface de Chat para o Servi√ßo LLM

Objetivo: construir uma UI de chat com Streamlit que consome
a API do servi√ßo LLM rodando no Cloud Run.

Siga os coment√°rios marcados com TODO para implementar cada parte.
N√£o existe uma √∫nica forma certa ‚Äî use a estrutura abaixo como guia.

Depend√™ncias:
    pip install streamlit requests

Como rodar:
    export API_URL=https://seu-servico-xxxx-uc.a.run.app
    streamlit run ui_llm_service.py
"""

# TODO: importe as bibliotecas necess√°rias
# Dica: voc√™ vai precisar de streamlit e requests

import streamlit as st
import requests
import os

# ------------------------------------------------------------
# CONFIGURA√á√ÉO DA P√ÅGINA
# Dica: st.set_page_config() deve ser a primeira chamada Streamlit
# ------------------------------------------------------------
st.set_page_config(page_title="LLM ChatBot", layout="wide")
                   
# TODO: configure o t√≠tulo da p√°gina e um √≠cone (opcional)


# ------------------------------------------------------------
# T√çTULO E DESCRI√á√ÉO
# ------------------------------------------------------------

# TODO: adicione um t√≠tulo e uma breve descri√ß√£o do que este chat faz
st.title("ü§ñ Interface de Servi√ßo LLM")
st.caption("Conectado ao Cloud Run + Gemini. Assistente virtual para responder todas suas perguntas.")

# ------------------------------------------------------------
# URL DA API
# Dica: nunca cole a URL diretamente no c√≥digo.
#       Leia de uma vari√°vel de ambiente com os.getenv().
#       Defina um valor padr√£o para facilitar testes locais.
# ------------------------------------------------------------
API_URL = os.getenv("https://api-blackbox-68490838153.us-central1.run.app"," http://localhost:8080")
ENDPOINT = f"https://api-blackbox-68490838153.us-central1.run.app/chat"
st.info(f"Conectado em: https://api-blackbox-68490838153.us-central1.run.app")
# TODO: leia a vari√°vel de ambiente API_URL


# ------------------------------------------------------------
# HIST√ìRICO DE MENSAGENS
# Para que o chat "lembre" das mensagens anteriores durante
# a sess√£o, voc√™ precisa armazen√°-las em st.session_state.
#
# Estrutura sugerida para cada mensagem:
#   {"role": "user" | "assistant", "content": "texto aqui"}
#
# Dica: inicialize a lista apenas se ela ainda n√£o existir.
# ------------------------------------------------------------

# TODO: inicialize st.session_state["messages"] se necess√°rio
if "messages" not in st.session_state:
    st.session_state.messages = []
with st.sidebar:
    st.header("Configura√ß√µes")
    if st.button("Limpar Hist√≥rico"):
        st.session_state["messages"] = []
        st.rerun()
    st.caption(f"Conectado em: {API_URL}")
# ------------------------------------------------------------
# EXIBI√á√ÉO DO HIST√ìRICO
# Renderize as mensagens j√° existentes na tela.
# Dica: st.chat_message(role) cria o bal√£o correto para cada papel.
# ------------------------------------------------------------

# TODO: percorra st.session_state["messages"] e exiba cada uma

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ------------------------------------------------------------
# FUN√á√ÉO DE CHAMADA √Ä API
# Encapsule a l√≥gica HTTP em uma fun√ß√£o separada.
# Isso facilita testes e deixa o c√≥digo mais organizado.
#
# Assinatura sugerida:
#   def call_llm(messages: list[dict]) -> str
#
# O que ela deve fazer:
#   1. Montar o payload no formato que a API espera
#      (consulte /docs do seu servi√ßo para ver o schema)
#   2. Fazer um POST para {API_URL}/chat
#   3. Extrair e retornar apenas o texto da resposta
#   4. Em caso de erro, retornar uma mensagem amig√°vel
#      (n√£o deixe o erro estourar na tela do usu√°rio)
#
# Dica: use requests.post() com o par√¢metro json= para o payload
# Dica: inspecione response.json() para ver o que a API retorna
# ------------------------------------------------------------

# TODO: implemente a fun√ß√£o call_llm

def call_llm(messages):
    payload ={
            "messages": [{"role": "user", "content": prompt}],
            "model": "gemini-2.5-flash"
            }
    try:
            response = requests.post(
                ENDPOINT,
                json=payload,
                timeout=30 
            ) 
            
            if response.status_code == 200:
                return response.json().get("message").get("content")
            else:
                return f"Erro na API ({response.status_code}): {response.text}"
            
    except requests.exceptions.RequestException as e:
        return f"Falha de conex√£o: {e}"

# ------------------------------------------------------------
# CAIXA DE ENTRADA DO USU√ÅRIO
# Dica: st.chat_input() fica fixo na parte inferior da tela
#       e retorna o texto digitado (ou None se vazio).
# ------------------------------------------------------------
if prompt := st.chat_input("Ol√°! Como posso ajudar voc√™ hoje?"):

    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("O Assistente est√° processando..."):

            resposta_llm = call_llm(st.session_state.messages)
            
            st.markdown(resposta_llm)
    
    st.session_state.messages.append({"role": "assistant", "content": resposta_llm})

# TODO: capture a entrada do usu√°rio com st.chat_input()

# Quando o usu√°rio enviar uma mensagem, voc√™ deve:
#   1. Adicion√°-la ao hist√≥rico (role: "user")
#   2. Exibi-la na tela imediatamente
#   3. Chamar a fun√ß√£o call_llm com o hist√≥rico completo
#   4. Adicionar a resposta ao hist√≥rico (role: "assistant")
#   5. Exibir a resposta na tela

# TODO: implemente o fluxo acima


# ------------------------------------------------------------
# DICAS FINAIS
#
# - st.spinner("...") exibe um indicador de carregamento
#   enquanto a API responde ‚Äî melhora muito a experi√™ncia
#
# - st.error("...") exibe mensagens de erro em vermelho
#
# - Se quiser limpar o hist√≥rico, st.button("Nova conversa")
#   combinado com del st.session_state["messages"] funciona bem
#
# - Explore st.sidebar para colocar configura√ß√µes (ex: URL da API,
#   temperatura do modelo) fora da √°rea principal do chat
# ------------------------------------------------------------
