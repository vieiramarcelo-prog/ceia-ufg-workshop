services:
  # 1. Frontend (Nginx)
  frontend:
    image: nginx:alpine
    container_name: ch2-frontend
    ports:
      - "80:80"
    volumes:
      - ./frontend:/usr/share/nginx/html
      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      api:
        condition: service_started

  # 2. Main API (Orchestrator)
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ch2-api
    env_file:
      - .env
    ports:
      - "8001:8000"
    depends_on:
      qdrant:
        condition: service_started
      llm_service:
        condition: service_healthy
    environment:
      - QDRANT_HOST=qdrant
      - LLM_API_URL=http://llm_service:8000/v1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  # 3. LLM Service (Simulated vLLM)
  llm_service:
    build:
      context: .
      dockerfile: Dockerfile.llm
    container_name: ch2-llm
    environment:
      - MODEL_PATH=/app/models/qwen2.5-1.5b-instruct-q4_k_m.gguf
      - HOST=0.0.0.0
      - PORT=8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
      interval: 10s
      timeout: 10s
      retries: 50
      start_period: 60s

  # 4. Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    container_name: ch2-qdrant
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'cat < /dev/tcp/localhost/6333'"] 
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 20s

volumes:
  qdrant_data:
